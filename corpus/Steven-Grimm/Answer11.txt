 Viktor Toth's answer covers a bunch of general principles. Another one is to look at performance from the top down.What I mean by that: say you have some code that searches a large data set and it's too slow. You can do a bunch of profiling (and that's almost always the right place to start) and discover that a particular inner loop is where you're spending most of your time. You might focus your efforts on making that small chunk of code run as fast as it possibly can. In a lot of cases this kind of targeted optimization can get you some impressive speedups, and when people talk about optimization this is usually the kind of thing they mean.But it should be the last step of your optimization process, not the first. Before you look at that inner loop, ask yourself if all the work the code is doing is even required by the user. For example, maybe you only need to search 10% of the items with an estimate of how many additional search results there are. Boom, massive speedup. This kind of falls under the principle, "The fastest code is the code that never needs to run at all."After that, see if the approach you're taking is the best one. For example, maybe you're using an O(n) algorithm where an O(n log n) one would also work. No amount of inner-loop optimization will beat switching to a lower order of complexity for a sufficiently large input. Your profiling data is still useful here, though, in that it'll tell you which of the O(n) algorithms in your code are actually causing problems; algorithms that run in polynomial time are perfectly fine if the inputs are guaranteed to be small.Only after you've ensured that you need to do the work at all, that you've identified the source of the performance problem, and that you're not choosing algorithms that are slow by nature, should you dive into language-specific micro-optimizations. You've probably seen the Knuth quote about premature optimization (even though it's usually quoted out of context). Answering the high-level questions is how you know when little fiddly kinds of optimization are no longer premature.