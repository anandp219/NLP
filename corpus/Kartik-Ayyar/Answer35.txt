 While I love the rigor of great algorithms books and in particular Introduction to Algorithms, one general problem that I've found with algorithms textbooks as an industry practitioner is that they focus a lot on advanced in core data structures you don't use often, and not enough on persistent data structures ones that you use a lot.For in core data structures in most cases lists, arrays and hash tables are by far the most commonly used structures. Sure once in a while you might see a skip list here and there or learn a particular implementation relies on a particular balanced tree, but for the most part getting your hands dirty with complex in core structures is rare.On the other hand, persistent data structures one encounters are usually now far, far more demanding than anything you see in a textbook, and usually also far less explained. There are concurrency, reliability and memory hierarchy friendliness issues that are very complex, and rarely captured well in textbooks.There might be some overlap with some of this material and a databases or OS class, but in those classes the algorithmic analysis is not that rigorous.So if I could have one feature request for the next book, it would be that there be a lot more additional material focused on persistent data structures.Update on what to remove:If I had to pick I'd vote for sorting networks, linear programming, FFT and computational geometry.